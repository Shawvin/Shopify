test$Survived<-predict(modFit,test)
write.csv(test[,1:2],"result1.csv",row.names = FALSE)
test$Survived<-predict(modFit2,test)
write.csv(test[,1:2],"result2.csv",row.names = FALSE)
test$Survived<-predict(modFit3,test)
table(test$Survived)
write.csv(test[,1:2],"result3.csv",row.names = FALSE)
n=nrow(train)
train<-total[1:n,]
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(library(caret))
suppressMessages(library(DMwR))
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(ggplot2))
suppressMessages(library(Hmisc))
suppressMessages(library(VIM))
if (!file.exists("train.csv"))
download.file("https://www.kaggle.com/c/titanic/download/train.csv","train.csv")
if (!file.exists("test.csv"))
download.file("https://www.kaggle.com/c/titanic/download/test.csv","test.csv")
train<-read.csv("train.csv", stringsAsFactors = FALSE)
test<-read.csv("test.csv", stringsAsFactors = FALSE)
names(train)
names(test)
test$Survived<-rep(NA,dim(test)[1])
total<-rbind(train,test)
str(total)
missingRate<-function(x)
{if (is.character(x))
{round(sum(x=="")/length(x)*100,3)}
else
{round(sum(is.na(x))/length(x)*100,3)}
}
missing<-sapply(total,missingRate)%>% data.frame()
names(missing)<-"missingRate"
missing$column<-rownames(missing)
rownames(missing)<-1:nrow(missing)
g<-ggplot(data.frame(missing),aes(x=reorder(column,missingRate),y=missingRate,fill=column))+geom_bar(stat="identity")+coord_flip(ylim=c(0,100))+geom_text(aes(label=missingRate),nudge_y=3)
g
imputeTotal<-kNN(total[-2],variable=c("Age","Fare","Embarked"),k=10)
total$Age<-imputeTotal$Age
total$Fare<-imputeTotal$Fare
total$Embarked<-imputeTotal$Embarked
total$Survived<-as.factor(total$Survived)
train$Survived<-as.factor(train$Survived)
dim(total)
n=nrow(train)
train<-total[1:n,]
table(total$Pclass)
ggplot(train,aes(Pclass,fill=Survived))+geom_bar(position="fill")
title<-function(x){
strsplit(x,"[,.]")[[1]][2]
}
total$Title<-sapply(as.character(total$Name),title)
table(total$Title)
total$Title<-gsub("Capt|Col|Don$|Jonkheer|Major|Sir","Mr",total$Title)
total$Title<-gsub("Dona|Mme|the Countess","Mrs",total$Title)
total$Title<-gsub("Lady|Mlle|Ms","Miss",total$Title)
table(total$Title)
table(total$Sex)
quantile(total$Age)
ggplot(train,aes(Sex,fill=Survived))+geom_bar(position="fill")
ggplot(train,aes(cut2(Age,18),fill=Survived))+geom_bar(position="fill")
ggplot(train,aes(SibSp,fill=Survived))+geom_bar(position="fill")
ggplot(train,aes(Parch,fill=Survived))+geom_bar(position="fill")
str(total$Ticket)
tnum<-table(total$Ticket)
TicketType<-function(x){
ifelse(tnum[x]>1,paste(tnum[x],"Shared",sep=""),"Single")
}
total$TicketType<-as.factor(sapply(as.character(total$Ticket),TicketType))
n=nrow(train)
train<-total[1:n,]
test<-total[-(1:n),]
traincontrol<-trainControl(method="repeatedcv")
traindata<-train[,-c(1,4,9,11)]
modFit<-train(as.factor(Survived)~.,data=traindata,method="rf",trControl=traincontrol)
modFit2<-train(as.factor(Survived)~.,data=traindata,method="rpart",trControl=traincontrol)
modFit3<-train(as.factor(Survived)~.,data=traindata,method="gbm",trControl=traincontrol,verbose=FALSE)
modFit
modFit2
modFit3
test$Survived<-predict(modFit,test)
write.csv(test[,1:2],"result1.csv",row.names = FALSE)
test$Survived<-predict(modFit2,test)
write.csv(test[,1:2],"result2.csv",row.names = FALSE)
test$Survived<-predict(modFit3,test)
table(test$Survived)
write.csv(test[,1:2],"result3.csv",row.names = FALSE)
modFit4<-train(as.factor(Survived)~.,data=traindata,method="nnet",trControl=traincontrol)
modFit3<-train(as.factor(Survived)~.,data=traindata,method="gbm",trControl=traincontrol,verbose=FALSE)
modFit4<-train(as.factor(Survived)~.,data=traindata,method="nnet",trControl=traincontrol,verbose=FALSE)
modFit4
test$Survived<-predict(modFit4,test)
table(test$Survived)
write.csv(test[,1:2],"result1.csv",row.names = FALSE)
test$Survived<-predict(modFit2,test)
table(test$Survived)
getwd()
test$Survived<-predict(modFit4,test)
table(test$Survived)
write.csv(test[,1:2],"result4.csv",row.names = FALSE)
install.packages(c("cowplot", "ggthemes", "usmap"))
head(iris)
svd1=svd(iris[1:4])
head(iris[1:4])
summary(svd1)
svd1$u
svd1$v
z=iris[1:4]*t(v[,1])
z=iris[1:4]*t(svd1$v[,1])
head(z)
z=iris[1:4]*v[,1]
z=iris[1:4]*svd1$v[,1]
head(z)
z=iris[1:4]*svd1$v[1]
head(z)
z=iris[1:4]%*%svd1$v[1]
z=iris[1:4] %*% svd1$v[1]
svd1$v[1]
svd1$v
svd1$v[1,]
svd1$v[1]
svd1$v[,1]
z=iris[1:4] %*% t(svd1$v[,1])
class(svd1$v)
class(iris[1:4])
z=matrix(iris[1:4]) %*% t(svd1$v[,1])
class(matrix(iris[1:4]))
z=(matrix(iris[1:4])) %*% t(svd1$v[,1])
dim(t(svd1$v[,1]))
dim(svd1$v[,1])
dim(svd1$v)
pca(iris[1:4])
?pca
??pca
pccomp(iris[1:4])
prcomp(iris[1:4])
svd1$d
dnorm(0,0,sd=2)
pnorm(2)
pnorm(2,0,1)
pnorm(2,0,2)
testM<-iris[1:4]
testM<-data.matrix(testM)
dim(testM)
test[1,]
testM[1,]
scaled_M<-scale(testM)
pnorm(scaled_M[1,])
scaled_M[1,]
sum(scaled_M,2)
?sum
rowsum(scaled_M)
rowSum(scaled_M)
?rowsum
rowSums(scaled_M)
?rowSums
product(pnorm(scaled_M[1,]))
prod(pnorm(scaled_M[1,]))
prod(pnorm(scaled_M[1:10,]))
rowProds(pnorm(scaled_M))
?rowProds
??rowProds
apply(pnorm(scaled_M),1,prod))
apply(pnorm(scaled_M),1,prod)\
apply(pnorm(scaled_M),1,prod)
p=colorRampPalette("red","green","blue")
p=colorRampPalette(c("red","green","blue"))
p(3)
p(6)
p(7)
showMe(p(7))
p2=colorRamp(c("red","green","blue"))
p2(0.5)
p2(0.3)
p2(1)
p2(c(0.1,0.1,0.1))
show_col(p(6))
sample.int
pix=sample.int(255,300)
pix=sample.int(255,300,replace=TRUE)
dim(pix)
length(pix)
pixel=matrix(pix,nrow=10,ncol=10)
dim(pix)
dim(pixel)
pixel
?array
?matrix
pixel=matrix(pix,c(10,10,3))
dim(pixel)
pixel=array(pix,c(10,10,3))
dim(pixel)
pixel[,,1]
pixel[,,2]
?dput
pixel2=matrix(pixel,nrow=1)
dim(pixel2)
head(pixel20)
head(pixel2)
# Installation guideline
# install.packages("keras")
# library(keras)
# install_keras(tensorflow="1.13.1")
library(keras)
is_keras_available()
a=c(3.5, 3.5 , 2.5)
b=c(4.5, 4, 1)
cov(a,b)
corr(a,b)
cor(a,b)
cor(a,b)*sd(a)*sd(b)
a=seq(9)
a
b=seq(9,1,-1)
b
cor(a,b)
cov(a,b)
78512+180+168655+801228
a=rnorm(100,0,1)
b=rnorm(100,3,2)
?t.test
t.test(a,b, var.equal = TRUE)
t.test(a,b)
summary(t.test(a,b, var.equal = TRUE))
3/12.863*sqrt(198)
3/12.863*sqrt(50)
sqrt(2.5)
mean(b-a)/12.863*sqrt(50)
library(tm)
library(stringr)
library(SnowballC)
library(slam)
library(dplyr)
library(Matrix)
library(tidyr)
########### To create the User-Ratings Matrix
# Import Reviews.csv
raw_events <- read.csv("reviews.csv", header=TRUE, sep=",") # transaction format!
raw_events[1,]
names(raw_events)
events = raw_events[c('author','app_id','rating')]
# Count the number of unique apps and reviewers
length(unique(events$app_id)) # 3733 apps
length(unique(events$author)) # 299,316 reviewers
# Select only the active reviewers (>= 10 reviews)
ucnts = aggregate(app_id ~ author, data = events, FUN=length)
colnames(ucnts) = c("author","numitems")
activeusers = ucnts$author[ucnts$numitems >= 10]
length(activeusers) # 1338 active reviewers
active_events = events[events$author %in% activeusers,]
length(unique(active_events$app_id)) # 1946 apps
dim(active_events) # Remaining no of reviews = 19418
head(active_events)
# Create User-Ratings Matrix for active reviewers
active_events <- active_events %>% group_by(author,app_id) %>%
summarize(rating=mean(rating))
users <- spread(active_events,app_id,rating,fill=0)
users <- users[-1,]
users_matrix <- as.matrix(users)
###########
# Read Apps Data
apps <- read.csv("apps.csv", stringsAsFactor=FALSE, encoding="UTF-8")
apps <- apps %>% rename(app_id = id)
head(apps)
dim(apps)
# Read key_benefits Data, and join text from title and description by app_id
key_benefits <- read.csv("key_benefits.csv", stringsAsFactor=FALSE, encoding="UTF-8")
key_benefits$titledescription <- paste(key_benefits$title, key_benefits$description,sep=" ")
key_benefits2 <- aggregate(titledescription ~ app_id, data = key_benefits, paste, collapse = " ")
# Read apps_categories Data
apps_categories <- read.csv("apps_categories.csv", stringsAsFactor=FALSE, encoding="UTF-8")
# Read categories Data
categories <- read.csv("categories.csv", stringsAsFactor=FALSE, encoding="UTF-8")
categories <- categories %>% rename(category_id = id, app_category = title)
# Add key_benefits text to apps dataframe
apps <- left_join(apps,key_benefits2, by="app_id")
dim(apps)
apps$text <- paste(apps$description, apps$tagline, apps$titledescription, sep=" ")
# Add category feature to apps dataframe
# apps <- inner_join(apps,apps_categories, by="app_id")
# apps <- inner_join(apps,categories, by="category_id")
# head(apps)
# Keep Title and Description Columns
apps_subset <- apps[, c('app_id','title', 'text')]
head(apps_subset)
# Filter this apps_subset with the truncated apps list
apps_subset <- apps_subset[apps_subset$app_id %in% unique(active_events$app_id),]
head(apps_subset)
dim(apps_subset)
# Remove non-ASCII characters with space, replace \n with space
apps_subset$title <- iconv(apps_subset$title, "UTF-8", "ASCII",sub='')
apps_subset$text <- iconv(apps_subset$text, "UTF-8", "ASCII",sub='')
apps_subset$text <- str_replace_all(apps_subset$text, "[\n]" , "")
apps_subset[10,] # Test case to check if replace was successful
# Text Pre-processing
corpus <- VCorpus(VectorSource(apps_subset$text))
for(i in 1:5){
print(corpus[[i]][1])
}
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
corpus <- tm_map(corpus, stripWhitespace)
# Create Document Term Matrix
dtm <- DocumentTermMatrix(corpus)
dtm_ti <- weightTfIdf(dtm)
dtm_ti
setwd("C:/Users/Wang Xiaoyuan/Desktop/Shopify")
library(tm)
library(stringr)
library(SnowballC)
library(slam)
library(dplyr)
library(Matrix)
library(tidyr)
########### To create the User-Ratings Matrix
# Import Reviews.csv
raw_events <- read.csv("reviews.csv", header=TRUE, sep=",") # transaction format!
raw_events[1,]
names(raw_events)
events = raw_events[c('author','app_id','rating')]
# Count the number of unique apps and reviewers
length(unique(events$app_id)) # 3733 apps
length(unique(events$author)) # 299,316 reviewers
# Select only the active reviewers (>= 10 reviews)
ucnts = aggregate(app_id ~ author, data = events, FUN=length)
colnames(ucnts) = c("author","numitems")
activeusers = ucnts$author[ucnts$numitems >= 10]
length(activeusers) # 1338 active reviewers
active_events = events[events$author %in% activeusers,]
length(unique(active_events$app_id)) # 1946 apps
dim(active_events) # Remaining no of reviews = 19418
head(active_events)
# Create User-Ratings Matrix for active reviewers
active_events <- active_events %>% group_by(author,app_id) %>%
summarize(rating=mean(rating))
users <- spread(active_events,app_id,rating,fill=0)
users <- users[-1,]
users_matrix <- as.matrix(users)
###########
# Read Apps Data
apps <- read.csv("apps.csv", stringsAsFactor=FALSE, encoding="UTF-8")
apps <- apps %>% rename(app_id = id)
head(apps)
dim(apps)
# Read key_benefits Data, and join text from title and description by app_id
key_benefits <- read.csv("key_benefits.csv", stringsAsFactor=FALSE, encoding="UTF-8")
key_benefits$titledescription <- paste(key_benefits$title, key_benefits$description,sep=" ")
key_benefits2 <- aggregate(titledescription ~ app_id, data = key_benefits, paste, collapse = " ")
# Read apps_categories Data
apps_categories <- read.csv("apps_categories.csv", stringsAsFactor=FALSE, encoding="UTF-8")
# Read categories Data
categories <- read.csv("categories.csv", stringsAsFactor=FALSE, encoding="UTF-8")
categories <- categories %>% rename(category_id = id, app_category = title)
# Add key_benefits text to apps dataframe
apps <- left_join(apps,key_benefits2, by="app_id")
dim(apps)
apps$text <- paste(apps$description, apps$tagline, apps$titledescription, sep=" ")
# Add category feature to apps dataframe
# apps <- inner_join(apps,apps_categories, by="app_id")
# apps <- inner_join(apps,categories, by="category_id")
# head(apps)
# Keep Title and Description Columns
apps_subset <- apps[, c('app_id','title', 'text')]
head(apps_subset)
# Filter this apps_subset with the truncated apps list
apps_subset <- apps_subset[apps_subset$app_id %in% unique(active_events$app_id),]
head(apps_subset)
dim(apps_subset)
# Remove non-ASCII characters with space, replace \n with space
apps_subset$title <- iconv(apps_subset$title, "UTF-8", "ASCII",sub='')
apps_subset$text <- iconv(apps_subset$text, "UTF-8", "ASCII",sub='')
apps_subset$text <- str_replace_all(apps_subset$text, "[\n]" , "")
apps_subset[10,] # Test case to check if replace was successful
# Text Pre-processing
corpus <- VCorpus(VectorSource(apps_subset$text))
for(i in 1:5){
print(corpus[[i]][1])
}
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
corpus <- tm_map(corpus, stripWhitespace)
# Create Document Term Matrix
dtm <- DocumentTermMatrix(corpus)
dtm_ti <- weightTfIdf(dtm)
dtm_ti
# Convert to Dense Matrix, add app_id column, sort by app_id
dtm_ti_densematrix<-as.matrix(dtm_ti)
shiny::runApp('Recommendation')
getwd()
dir()
dat<-read.csv("apps.csv")
dim(dat)
head(dat)
View(dat)
View(dat)
runApp('Recommendation')
dir()
runApp('Recommendation')
dat<-read.csv("apps.csv")
dat<-read.csv("apps.csv")
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
View(dat)
runApp('Recommendation')
View(dat)
View(dat)
View(dat)
dat$icon[1]
readPNG(getURLContent(dat$icon[1]))
install.packages("png")
library("png")
readPNG(getURLContent(dat$icon[1]))
?getURLContent
??getURLContent
install.packages("magick")
library(magick)
print(image_read(dat$icon[1]))
" + dat$icon[1] +"
runApp('Recommendation')
install.packages("shinyjs")
runApp('Recommendation')
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
dat$icon[1]
runApp('Recommendation')
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp('Recommendation')
dat$icon[1]
runApp('Recommendation')
dat$icon[1:10]
runApp('Recommendation')
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp()
runApp('Recommendation')
dat$icon[1]
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp()
runApp('Recommendation')
library(shinyjs)
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp()
runApp('Recommendation')
runApp('Recommendation')
lapply(dat$icon[1:10], function(file){print(file)})
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
runApp('Recommendation')
length(icon)
length(unique(data$icon))
length(unique(dat$icon))
icons<-unique(dat$icon)
runApp('Recommendation')
runApp('Recommendation')
#convert the app id and app category to wide format
apps_cat<-read.csv("apps_categories.csv")
head(apps_cat)
cat<-read.csv("categories.csv")
cat
unique(cat$title)
as.character(unique(cat$title))
runApp('Recommendation')
