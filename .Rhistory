model_train_in<-Arima(training_in, order=c(1,2,1))
summary(model_train_in)
model_train_in<-Arima(training_in, order=c(1,2,1))
summary(model_train_in)
coeftest(model_train_in)
arima_model_train_in<-ARIMA(training_in, order=c(1,2,0))
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals((arima_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals((arima_model_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals(arima_model_train_in)
smooth_model_train_in<-ets(training_in)
summary(smooth_model_train_in)
smooth_model_train_in<-ets(training_in)
summary(smooth_model_train_in)
checkresiduals(smooth_model_train_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
data.frame(val_in, pred_arima_in, pred_smooth_in)
pred_arima_in
pred_arima_in$mean
pred_arima_in$mean[1]
pred_arima_in$mean-val_in
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuray(pred_arima_in, val_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(pred_smooth_in, val_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(pred_smooth_in, val_in)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
training_ch %>% diff() %>% ggtsdisplay()
ts_data<-spread(transformed_data,Country,LaborRate)
pacman::p_load(forecast, tseries, fUnitRoots, tidyverse, lmtest, fastDummies)
ts_China<-ts(ts_data$China, start = 1980, frequency = 1)
ts_India<-ts(ts_data$India, start = 1980, frequency = 1)
ts_sg<-ts(ts_data$Singapore,start = 1980, frequency = 1)
autoplot(ts_China)
training_ch<-subset(ts_China, end=26)
val_ch<-subset(ts_China, start=27)
adfTest(training_ch)
training_ch %>% diff() %>% ggtsdisplay()
training_ch %>% diff() %>% adfTest()
training_ch %>% diff() %>% diff() %>% ggtsdisplay()
training_ch %>% diff() %>% diff() %>% adfTest()
model_train_ch<-Arima(training_ch, order=c(1,2,1))
summary(model_train_ch)
coeftest(model_train_ch)
arima_model_train_ch<-Arima(training_ch, order=c(0,2,0))
summary(arima_model_train_ch)
checkresiduals(arima_model_train_ch)
smooth_model_train_ch<-ets(training_ch)
summary(smooth_model_train_ch)
checkresiduals(smooth_model_train_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(arima_model_train_ch, val_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(arima_model_train_ch, val_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(pred_arima_ch, val_ch)
accuracy(pred_smooth_ch, val_ch)
final_model_ch<-Arima(ts_China, order = c(0,2,0))
final_model_ch<-Arima(ts_China, order = c(0,2,0))
checkresiduals(final_model_ch)
final_model_ch<-Arima(ts_China, order = c(0,2,0))
checkresiduals(final_model_ch)
pred_ch<-forecast(final_model_ch, h=2)
pred_ch
final_model_in<-ets(ts_India)
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
?ets
summary(smooth_model_train_in)
final_model_in<-ets(ts_India, model="MAN")
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
final_model_in<-ets(ts_India)
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
final_model_in<-ets(ts_India, method="MAN")
final_model_in<-ets(ts_India, model="MAN")
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
summary(auto.arima(training_in))
autoplot(ts_Singapore)
ts_data<-spread(transformed_data,Country,LaborRate)
pacman::p_load(forecast, tseries, fUnitRoots, tidyverse, lmtest, fastDummies)
ts_China<-ts(ts_data$China, start = 1980, frequency = 1)
ts_India<-ts(ts_data$India, start = 1980, frequency = 1)
ts_Singapore<-ts(ts_data$Singapore,start = 1980, frequency = 1)
autoplot(ts_Singapore)
training_sg<-subset(ts_Singapore, end=26)
val_sg<-subset(ts_Singapore, start=27)
adfTest(training_sg)
summary(auto.arima(training_sg))
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% adfTest()
model_train_sg<-Arima(training_sg, order=c(1,1,1))
summary(model_train_sg)
coeftest(model_train_sg)
summary(auto.arima(training_sg))
summary(auto.arima(training_in))
summary(auto.arima(training_ch))
summary(auto.arima(ts_Singapore))
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% adfTest()
training_sg %>% diff() %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% diff() %>% adfTest()
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
autoplot(ts_Singapore)
training_sg<-subset(ts_Singapore, end=26)
val_sg<-subset(ts_Singapore, start=27)
adfTest(training_sg)
summary(auto.arima(training_sg))
coeftest(auto.arima(training_sg))
model_train_sg<-Arima(training_sg, order=c(1,1,1))
summary(model_train_sg)
coeftest(model_train_sg)
model_train_sg<-Arima(training_sg, order=c(1,1,0))
summary(model_train_sg)
coeftest(model_train_sg)
?Arima
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
arima_model_train_sg<-model_train_sg
checkresiduals(arima_model_train_sg)
smooth_model_train_sg<-ets(training_sg)
summary(smooth_model_train_sg)
?ets
smooth_model_train_sg<-ets(training_sg)
summary(smooth_model_train_sg)
checkresiduals(smooth_model_train_sg)
pred_arima_sg<-forecast(arima_model_train_sg, h=2)
pred_smooth_sg<-forecast(smooth_model_train_sg, h=2)
accuracy(pred_arima_sg, val_sg)
accuracy(pred_smooth_sg, val_sg)
final_model_sg<-Arima(ts_Singapore, order = c(1,2,1))
summary(final_model_sg)
pred_sg<-forecast(final_model_sg, h=2)
pred_sg
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR, caretEnsemble)
data<-read.csv("reports.csv", stringsAsFactors = FALSE)
dim(data)
summary(data)
table(data$Insp=="unkn")
table(data$Insp)
rate<-1270/15732*100
rate
md.pattern(data)
md.pattern(data[data$Insp!="unkn",])
md.pattern(data[data$Insp=="fraud",])
ggplot(data[data$Insp!="unkn",], aes(Quant, Val, color=Insp))+
geom_point(alpha=0.5, na.rm = TRUE, size=0.5)+
scale_x_continuous(trans= "log") + scale_y_continuous(trans= "log")
data$Missing<-"None Missng"
data[is.na(data$Quant),]$Missing<-"Quant Missing"
data[is.na(data$Val),]$Missing<-"Val Missing"
data[is.na(data$Quant)&is.na(data$Val),]$Missing<-"Both Missing"
table(data$Missing)
data <- data %>% filter(Missing!="Both Missing")
table(data$Missing)
data$unit_price<-data$Val/data$Quant
price_data<-data %>% filter(Insp!="fraud") %>% group_by(Prod) %>%
summarise(med_price=median(unit_price, na.rm = TRUE),iqr=IQR(unit_price, na.rm = TRUE))
table(is.na(price_data$med_price))
price_data<-price_data %>% filter(!is.na(med_price))
data <- data %>% inner_join(price_data, by="Prod")
noQuant<-data$Missing=="Quant Missing"
data[noQuant, "Quant"]=ceiling(data[noQuant, "Val"]/data[noQuant, "med_price"])
noVal<-data$Missing=="Val Missing"
data[noVal, "Val"]=data[noVal, "Quant"]*data[noVal, "med_price"]
data$unit_price<-data$Val/data$Quant
md.pattern(data)
data$relative_price<-2*(data$unit_price-data$med_price)/(data$unit_price+data$med_price)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
DTpred<-predict(DTmodel, validation, type="class")
DTpred<-predict(DTmodel, validation, type="class")
confusionMatrix(table(validation$Insp, DTpred))
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
RFpred<-predict(RFmodel, validation, type="class")
confusionMatrix(table(validation$Insp, RFpred))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
confusionMatrix(table(validation$Insp, pred$class))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
confusionMatrix(table(validation$Insp, pred$class))
## caret Ensemble to compare multiple models
algorithmList<-c("rpart","rf", "adaboost")
models<-caretList(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, methodList = algorithmList)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR)
data<-read.csv("reports.csv", stringsAsFactors = FALSE)
dim(data)
summary(data)
table(data$Insp=="unkn")
table(data$Insp)
rate<-1270/15732*100
rate
md.pattern(data)
md.pattern(data[data$Insp!="unkn",])
md.pattern(data[data$Insp=="fraud",])
ggplot(data[data$Insp!="unkn",], aes(Quant, Val, color=Insp))+
geom_point(alpha=0.5, na.rm = TRUE, size=0.5)+
scale_x_continuous(trans= "log") + scale_y_continuous(trans= "log")
data$Missing<-"None Missng"
data[is.na(data$Quant),]$Missing<-"Quant Missing"
data[is.na(data$Val),]$Missing<-"Val Missing"
data[is.na(data$Quant)&is.na(data$Val),]$Missing<-"Both Missing"
table(data$Missing)
data <- data %>% filter(Missing!="Both Missing")
table(data$Missing)
data$unit_price<-data$Val/data$Quant
price_data<-data %>% filter(Insp!="fraud") %>% group_by(Prod) %>%
summarise(med_price=median(unit_price, na.rm = TRUE),iqr=IQR(unit_price, na.rm = TRUE))
table(is.na(price_data$med_price))
price_data<-price_data %>% filter(!is.na(med_price))
data <- data %>% inner_join(price_data, by="Prod")
noQuant<-data$Missing=="Quant Missing"
data[noQuant, "Quant"]=ceiling(data[noQuant, "Val"]/data[noQuant, "med_price"])
noVal<-data$Missing=="Val Missing"
data[noVal, "Val"]=data[noVal, "Quant"]*data[noVal, "med_price"]
data$unit_price<-data$Val/data$Quant
md.pattern(data)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
data$relative_price<-2*(data$unit_price-data$med_price)/(data$unit_price+data$med_price)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
DTpred<-predict(DTmodel, validation, type="class")
CM1<-confusionMatrix(table(validation$Insp, DTpred))
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
RFpred<-predict(RFmodel, validation, type="class")
CM2<-confusionMatrix(table(validation$Insp, RFpred))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
CM3<-confusionMatrix(table(validation$Insp, pred$class))
## compare the lift chart of three models
lift_result<-data.frame(Class=validation$Insp)
lift_result$DT<-predict(DTmodel, validation, type="prob")[,"fraud"]
lift_result$RF<-predict(RFmodel, validation, type="prob")[,"fraud"]
adapred<-predict(Adamodel, validation)
lift_result$Ada<-adapred$prob[,1]
head(lift_result)
trellis.par.set(caretTheme())
lift_obj<-lift(Class~DT+RF+Ada, data=lift_result)
ggplot(lift_obj, value=90)+scale_x_continuous(breaks = seq(0,100,10))
result<-resamples(CM1,CM2,CM3)
result<-resamples(list(CM1,CM2,CM3))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR, mlbench)
result<-resamples(list(CM1,CM2,CM3))
result<-resamples(list(DTmodel,RFmodel,Adamodel))
resamples(list(DTmodel,RFmodel,Adamodel))
DTmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training,method="rpart")
DTmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training,method="rpart")
DTpred<-predict(DTmodel, validation, type="class")
RFmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, method="rf")
X<-as.matrix(iris[1:150,1:4])
pcaX<-pca(X)
pcaX<-princomp(X)
svdX<-svd(X)
summary(pcaX)
str(pcaX)
pcaX$scale
pcaX$loadings
pcaX$scores
summary(svdX)
str(svdX)
irisPCA<-data.frame(pcaX$scores, iris$Species)
head(irisPCA)
library(ggplot2)
ggplot(irisPCA, aes(x=Comp.1, y=Comp.2, color=iris.Species))+geom_point()
pcaX$scale
svdX$v
pcaX$loadings
diag(d)
diag(svdX$d)
svdX$u*diag(svdX$d)
svdX$u %*% diag(svdX$d)
pcaX$scale
pcaX$loadings
diag(svdX$d) %*% t(diag(svd$d))
diag(svdX$d) %*% t(diag(svdX$d))
diag(svdX$d) %*% t(diag(svdX$v))
diag(svdX$d) %*% t(svdX$v)
pcaX$scores
svdX$v %*% t(svdX$v)
pcaX$scale
pcaX$loadings
c<-t(X) %*% X/149
svdc<-svd(c)
summary(svdc)
str(svdc)
svdc$u
svdc$v
head(pcaX$scores)
head(X %*% t(svdc$u))
head(X)
head(X %*% svdc$u)
head(pcaX$scores)
svdc$d
svdX$d
svdX$d^2/149
test<-data.matrix(seq(3),seq(3))
test
test<-data.matrix(seq(3),seq(3))
test
?data.matrix
seq(3)
test<-data.matrix(seq(3),seq(3)*2)
test
test<-data.matrix(x=seq(3),y=seq(3))
test<-data.frame(x=seq(3),y=seq(3))
test
pca(test)
prcomp(test)
pcatest<-prcomp(test)
pcatest$scale
pcatest$x
getwd()
install.packages("tidytext")
install.packages("shinyjs")
shiny::runApp('Desktop/Shopify/Recommendation')
shiny::runApp('Desktop/Shopify/Recommendation')
runApp('Desktop/Shopify/Recommendation')
setwd("~/Desktop/Shopify")
dir
ls
ls()
dir()
top6<-read.csv("hybrid_recommendation_top6.csv")
colnames(top6)
head(top6)
length(unique(top6$user_id))
userlist<-unique(top6$user_id)
top6<-read.csv("hybrid_recommendation_top6.csv", stringsAsFactors = FALSE)
userlist<-unique(top6$user_id)
activeuser_list<-userlist
rm(userlist)
head(activeuser_list)
setwd("~/Desktop/Shopify/Recommendation")
save(activeuser_list, file = "activeuser.RData")
shiny::runApp()
runApp()
rm(activeuser_list)
runApp()
runApp()
runApp()
load("~/Desktop/Shopify/Recommendation/app_icon.Rdata")
app_icons[1:6]
head(app_icons)
str(app_icons)
#write.csv(dat2, "app_icon.csv", row.names = FALSE)
save(app_icons, file="app_icons.Rdata")
runApp()
runApp()
#***********************
#3. active user list
#***********************
#read the csv file
top6<-read.csv("hybrid_recommendation_top6.csv", stringsAsFactors = FALSE)
runApp()
runApp()
runApp()
runApp()
length(unique(top6$app_id))
head(app_icons)
head(app_icon)
runApp()
##the app_icon file have been saved, it have the url for icon, title, rating and tagline for app display
load("app_icons.Rdata")
head(app_icons)
##read the apps csv
dat<-read.csv("apps.csv", encoding="UTF-8")
colnames(dat)
##obtain the columns we need
dat2<-dat[,c(3,6,7,8,11)] %>% unique()
##paste the title with ratings
dat2$titles<-paste(dat2$title, "\t(",dat2$rating, ")", sep="")
#write.csv(dat2, "app_icon.csv", row.names = FALSE)
save(app_icons, file="app_icons.Rdata")
rm(dat)
rm(dat2)
##the app_icon file have been saved, it have the url for icon, title, rating and tagline for app display
load("app_icons.Rdata")
View(app_icons)
rm(app_icons)
##read the apps csv
dat<-read.csv("apps.csv", encoding="UTF-8")
##obtain the columns we need
dat2<-dat[,c(3,6,7,8,11)] %>% unique()
View(dat2)
View(dat2)
##paste the title with ratings
dat2$titles<-paste(dat2$title, "\t(",dat2$rating, ")", sep="")
app_icons<-dat2
#write.csv(dat2, "app_icon.csv", row.names = FALSE)
save(app_icons, file="app_icons.Rdata")
View(app_icons)
View(app_icons)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(dat2)
View(dat2)
runApp()
runApp()
head(top6)
?split
test<-split(top6, user_id)
test<-split(top6, top6$user_id)
test[[1]]
test[[2]]
unique(top6$user_id)
length(unique(top6$user_id))
length(unique(top6$apps_id))
length(unique(top6$app_id))
dir()
top6<-read.csv("hybrid_recommendation_top6.csv")
test[[1]]
runApp()
setwd("~/Desktop/Shopify")
