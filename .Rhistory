?predict
?rpart::predict.rpart
pred<-predict(model1, data=validation)
)
pred<-predict(model1)
pred<-predict(model1, data=validation, type="class")
table(validation$insp, pred, positive="fraud")
training<-inspected[inTrain,]
inTrain<-createDataPartition(inspected$Insp, p=0.8, list = FALSE)
inspected<-data[data$Insp!="unkn",]
inTrain<-createDataPartition(inspected$Insp, p=0.8, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
model1<-rpart(Insp~Val+Quant+Missing+relative_price, data=training)
pred<-predict(model1, data=validation, type="class")
table(validation$insp, pred, positive="fraud")
table(validation$Insp, pred, positive="fraud")
table(validation$Insp, pred)
pred<-predict(model1, data=validation, type="class")
table(validation$Insp, pred)
length(pred)
length(validation$Insp)
pred<-predict(model1, validation, type="class")
table(validation$Insp, pred)
data<-read.csv("reports.csv", stringsAsFactors = FALSE)
dim(data)
str(data)
table(data$Insp=="unkn")
table(data$Insp)
rate<-1270/15732*100
rate
inspected<-data[data$Insp!="unkn",]
colMeans(is.na(data))*100
colMeans(is.na(inspected))
prop.table(table(is.na(inspected$Quant), is.na(inspected$Val))) * 100
prop.table(table(is.na(inspected$Quant), is.na(inspected$Val), inspected$Insp)) * 100
ggplot(inspected, aes(Quant, Val, color=Insp))+geom_point(alpha=0.5, na.rm = TRUE)+scale_x_continuous(trans = "log") + scale_y_continuous(trans = "log")
data$Missing<-"None"
data[is.na(data$Quant),]$Missing<-"Quant Missing"
data[is.na(data$Val),]$Missing<-"Val Missing"
data[is.na(data$Quant)&is.na(data$Val),]$Missing<-"Both Missing"
table(data$Missing)
data$unit_price<-data$Val/data$Quant
data<-data %>% group_by(Prod) %>% mutate(med_price=median(unit_price, na.rm = TRUE)) %>%
mutate(relative_price=2*(unit_price-med_price)/(unit_price + med_price)) %>%
select(ID, Prod, Quant, Val, Insp, Missing, relative_price)
ggplot(data, aes(Insp, relative_price, color=Insp)) +geom_jitter(na.rm = TRUE, alpha=0.5)
inspected<-data[data$Insp!="unkn",]
inTrain<-createDataPartition(inspected$Insp, p=0.8, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
model1<-rpart(Insp~Val+Quant+Missing+relative_price, data=training)
pred<-predict(model1, validation, type="class")
table(validation$Insp, pred)
?rpart
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, readxl, lubridate, caret, rpart, randomforest)
install.packages("randomforest")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, readxl, lubridate, caret, rpart, randomForest)
?rf
randomForest::randomForest()
model2<-randomForest(Insp~Val+Quant+Missing+relative_price, data=training)
, data=training
model2<-randomForest(Insp~Missing, data=training)
randomForest()
?randomForest
model2<-randomForest(Insp~Val+Quant+Missing+relative_price, data=training, na.action = na.omit)
model2<-randomForest(Insp~Val+Quant+Missing+relative_price, data=training, na.action = na.omit)
model2<-randomForest(Insp~Val+Quant+Missing+relative_price, data=training)
model2<-randomForest(Insp~Val+Quant+Missing+relative_price, data=training,na.action = na.omit)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, caret, rpart, randomForest)
smooth_model_train_ch<-ets(training_ch)
smooth_model_train_ch<-ets(training_ch)
raw_data<-read_xlsx("LaborRates.xlsx")
dim(raw_data)
head(raw_data)
transformed_data<-raw_data %>% filter(Country %in% c("China","India","Singapore")) %>%
gather("Year","LaborRate", -Country)
transformed_data$Year<-as.numeric(transformed_data$Year)
ggplot(transformed_data, aes(Year,LaborRate, color=Country))+geom_line(lwd=0.5)+geom_point()
ts_data<-spread(transformed_data,Country,LaborRate)
pacman::p_load(forecast, tseries, fUnitRoots, tidyverse, lmtest, fastDummies)
ts_China<-ts(ts_data$China, start = 1980, frequency = 1)
ts_India<-ts(ts_data$India, start = 1980, frequency = 1)
ts_sg<-ts(ts_data$Singapore,start = 1980, frequency = 1)
autoplot(ts_India)
training_in<-subset(ts_India, end=26)
val_in<-subset(ts_India, start=27)
adfTest(training_in)
training_in %>% diff() %>% adfTest()
training_in %>% diff() %>% diff() %>% adfTest()
training_in %>% diff() %>% ggtsdisplay()
training_in %>% diff() %>% adfTest()
training_in %>% diff() %>% diff() %>% ggtsdisplay()
training_in %>% diff() %>% diff() %>% adfTest()
model_train_in<-Arima(training_in, order=c(1,2,1))
summary(model_train_in)
model_train_in<-Arima(training_in, order=c(1,2,1))
summary(model_train_in)
coeftest(model_train_in)
arima_model_train_in<-ARIMA(training_in, order=c(1,2,0))
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals((arima_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals((arima_model_train_in)
arima_model_train_in<-Arima(training_in, order=c(1,2,0))
summary(arima_model_train_in)
checkresiduals(arima_model_train_in)
smooth_model_train_in<-ets(training_in)
summary(smooth_model_train_in)
smooth_model_train_in<-ets(training_in)
summary(smooth_model_train_in)
checkresiduals(smooth_model_train_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
data.frame(val_in, pred_arima_in, pred_smooth_in)
pred_arima_in
pred_arima_in$mean
pred_arima_in$mean[1]
pred_arima_in$mean-val_in
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuray(pred_arima_in, val_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(arima_model_train_in)
accuracy(smooth_model_train_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(pred_smooth_in, val_in)
pred_arima_in<-forecast(arima_model_train_in, h=2)
pred_smooth_in<-forecast(smooth_model_train_in,h=2)
accuracy(pred_arima_in, val_in)
accuracy(pred_smooth_in, val_in)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
training_ch %>% diff() %>% ggtsdisplay()
ts_data<-spread(transformed_data,Country,LaborRate)
pacman::p_load(forecast, tseries, fUnitRoots, tidyverse, lmtest, fastDummies)
ts_China<-ts(ts_data$China, start = 1980, frequency = 1)
ts_India<-ts(ts_data$India, start = 1980, frequency = 1)
ts_sg<-ts(ts_data$Singapore,start = 1980, frequency = 1)
autoplot(ts_China)
training_ch<-subset(ts_China, end=26)
val_ch<-subset(ts_China, start=27)
adfTest(training_ch)
training_ch %>% diff() %>% ggtsdisplay()
training_ch %>% diff() %>% adfTest()
training_ch %>% diff() %>% diff() %>% ggtsdisplay()
training_ch %>% diff() %>% diff() %>% adfTest()
model_train_ch<-Arima(training_ch, order=c(1,2,1))
summary(model_train_ch)
coeftest(model_train_ch)
arima_model_train_ch<-Arima(training_ch, order=c(0,2,0))
summary(arima_model_train_ch)
checkresiduals(arima_model_train_ch)
smooth_model_train_ch<-ets(training_ch)
summary(smooth_model_train_ch)
checkresiduals(smooth_model_train_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(arima_model_train_ch, val_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(arima_model_train_ch, val_ch)
pred_arima_ch<-forecast(arima_model_train_ch, h=2)
pred_smooth_ch<-forecast(smooth_model_train_ch, h=2)
accuracy(pred_arima_ch, val_ch)
accuracy(pred_smooth_ch, val_ch)
final_model_ch<-Arima(ts_China, order = c(0,2,0))
final_model_ch<-Arima(ts_China, order = c(0,2,0))
checkresiduals(final_model_ch)
final_model_ch<-Arima(ts_China, order = c(0,2,0))
checkresiduals(final_model_ch)
pred_ch<-forecast(final_model_ch, h=2)
pred_ch
final_model_in<-ets(ts_India)
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
?ets
summary(smooth_model_train_in)
final_model_in<-ets(ts_India, model="MAN")
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
final_model_in<-ets(ts_India)
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
final_model_in<-ets(ts_India, method="MAN")
final_model_in<-ets(ts_India, model="MAN")
summary(final_model_in)
checkresiduals(final_model_in)
pred_in<-forecast(final_model_in, h=2)
pred_in
summary(auto.arima(training_in))
autoplot(ts_Singapore)
ts_data<-spread(transformed_data,Country,LaborRate)
pacman::p_load(forecast, tseries, fUnitRoots, tidyverse, lmtest, fastDummies)
ts_China<-ts(ts_data$China, start = 1980, frequency = 1)
ts_India<-ts(ts_data$India, start = 1980, frequency = 1)
ts_Singapore<-ts(ts_data$Singapore,start = 1980, frequency = 1)
autoplot(ts_Singapore)
training_sg<-subset(ts_Singapore, end=26)
val_sg<-subset(ts_Singapore, start=27)
adfTest(training_sg)
summary(auto.arima(training_sg))
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% adfTest()
model_train_sg<-Arima(training_sg, order=c(1,1,1))
summary(model_train_sg)
coeftest(model_train_sg)
summary(auto.arima(training_sg))
summary(auto.arima(training_in))
summary(auto.arima(training_ch))
summary(auto.arima(ts_Singapore))
training_sg %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% adfTest()
training_sg %>% diff() %>% diff() %>% ggtsdisplay()
training_sg %>% diff() %>% diff() %>% adfTest()
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
autoplot(ts_Singapore)
training_sg<-subset(ts_Singapore, end=26)
val_sg<-subset(ts_Singapore, start=27)
adfTest(training_sg)
summary(auto.arima(training_sg))
coeftest(auto.arima(training_sg))
model_train_sg<-Arima(training_sg, order=c(1,1,1))
summary(model_train_sg)
coeftest(model_train_sg)
model_train_sg<-Arima(training_sg, order=c(1,1,0))
summary(model_train_sg)
coeftest(model_train_sg)
?Arima
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
model_train_sg<-Arima(training_sg, order=c(1,2,1))
summary(model_train_sg)
coeftest(model_train_sg)
arima_model_train_sg<-model_train_sg
checkresiduals(arima_model_train_sg)
smooth_model_train_sg<-ets(training_sg)
summary(smooth_model_train_sg)
?ets
smooth_model_train_sg<-ets(training_sg)
summary(smooth_model_train_sg)
checkresiduals(smooth_model_train_sg)
pred_arima_sg<-forecast(arima_model_train_sg, h=2)
pred_smooth_sg<-forecast(smooth_model_train_sg, h=2)
accuracy(pred_arima_sg, val_sg)
accuracy(pred_smooth_sg, val_sg)
final_model_sg<-Arima(ts_Singapore, order = c(1,2,1))
summary(final_model_sg)
pred_sg<-forecast(final_model_sg, h=2)
pred_sg
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR, caretEnsemble)
data<-read.csv("reports.csv", stringsAsFactors = FALSE)
dim(data)
summary(data)
table(data$Insp=="unkn")
table(data$Insp)
rate<-1270/15732*100
rate
md.pattern(data)
md.pattern(data[data$Insp!="unkn",])
md.pattern(data[data$Insp=="fraud",])
ggplot(data[data$Insp!="unkn",], aes(Quant, Val, color=Insp))+
geom_point(alpha=0.5, na.rm = TRUE, size=0.5)+
scale_x_continuous(trans= "log") + scale_y_continuous(trans= "log")
data$Missing<-"None Missng"
data[is.na(data$Quant),]$Missing<-"Quant Missing"
data[is.na(data$Val),]$Missing<-"Val Missing"
data[is.na(data$Quant)&is.na(data$Val),]$Missing<-"Both Missing"
table(data$Missing)
data <- data %>% filter(Missing!="Both Missing")
table(data$Missing)
data$unit_price<-data$Val/data$Quant
price_data<-data %>% filter(Insp!="fraud") %>% group_by(Prod) %>%
summarise(med_price=median(unit_price, na.rm = TRUE),iqr=IQR(unit_price, na.rm = TRUE))
table(is.na(price_data$med_price))
price_data<-price_data %>% filter(!is.na(med_price))
data <- data %>% inner_join(price_data, by="Prod")
noQuant<-data$Missing=="Quant Missing"
data[noQuant, "Quant"]=ceiling(data[noQuant, "Val"]/data[noQuant, "med_price"])
noVal<-data$Missing=="Val Missing"
data[noVal, "Val"]=data[noVal, "Quant"]*data[noVal, "med_price"]
data$unit_price<-data$Val/data$Quant
md.pattern(data)
data$relative_price<-2*(data$unit_price-data$med_price)/(data$unit_price+data$med_price)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
DTpred<-predict(DTmodel, validation, type="class")
DTpred<-predict(DTmodel, validation, type="class")
confusionMatrix(table(validation$Insp, DTpred))
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
RFpred<-predict(RFmodel, validation, type="class")
confusionMatrix(table(validation$Insp, RFpred))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
confusionMatrix(table(validation$Insp, pred$class))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
confusionMatrix(table(validation$Insp, pred$class))
## caret Ensemble to compare multiple models
algorithmList<-c("rpart","rf", "adaboost")
models<-caretList(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, methodList = algorithmList)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR)
data<-read.csv("reports.csv", stringsAsFactors = FALSE)
dim(data)
summary(data)
table(data$Insp=="unkn")
table(data$Insp)
rate<-1270/15732*100
rate
md.pattern(data)
md.pattern(data[data$Insp!="unkn",])
md.pattern(data[data$Insp=="fraud",])
ggplot(data[data$Insp!="unkn",], aes(Quant, Val, color=Insp))+
geom_point(alpha=0.5, na.rm = TRUE, size=0.5)+
scale_x_continuous(trans= "log") + scale_y_continuous(trans= "log")
data$Missing<-"None Missng"
data[is.na(data$Quant),]$Missing<-"Quant Missing"
data[is.na(data$Val),]$Missing<-"Val Missing"
data[is.na(data$Quant)&is.na(data$Val),]$Missing<-"Both Missing"
table(data$Missing)
data <- data %>% filter(Missing!="Both Missing")
table(data$Missing)
data$unit_price<-data$Val/data$Quant
price_data<-data %>% filter(Insp!="fraud") %>% group_by(Prod) %>%
summarise(med_price=median(unit_price, na.rm = TRUE),iqr=IQR(unit_price, na.rm = TRUE))
table(is.na(price_data$med_price))
price_data<-price_data %>% filter(!is.na(med_price))
data <- data %>% inner_join(price_data, by="Prod")
noQuant<-data$Missing=="Quant Missing"
data[noQuant, "Quant"]=ceiling(data[noQuant, "Val"]/data[noQuant, "med_price"])
noVal<-data$Missing=="Val Missing"
data[noVal, "Val"]=data[noVal, "Quant"]*data[noVal, "med_price"]
data$unit_price<-data$Val/data$Quant
md.pattern(data)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
data$relative_price<-2*(data$unit_price-data$med_price)/(data$unit_price+data$med_price)
data$Missing<-as.factor(data$Missing)
inspected<-data[data$Insp!="unkn",]
test<-data[data$Insp=="unkn",]
set.seed(1234)
inTrain<-createDataPartition(inspected$Insp, p=0.7, list = FALSE)
training<-inspected[inTrain,]
validation<-inspected[-inTrain,]
## build decision tree model
DTmodel<-rpart(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
DTpred<-predict(DTmodel, validation, type="class")
CM1<-confusionMatrix(table(validation$Insp, DTpred))
## build a random forest model
RFmodel<-randomForest(as.factor(training$Insp)~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training)
RFpred<-predict(RFmodel, validation, type="class")
CM2<-confusionMatrix(table(validation$Insp, RFpred))
## build adaptive boost model
Adamodel<-adaboost(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, nIter=2)
pred<-predict(Adamodel, validation)
CM3<-confusionMatrix(table(validation$Insp, pred$class))
## compare the lift chart of three models
lift_result<-data.frame(Class=validation$Insp)
lift_result$DT<-predict(DTmodel, validation, type="prob")[,"fraud"]
lift_result$RF<-predict(RFmodel, validation, type="prob")[,"fraud"]
adapred<-predict(Adamodel, validation)
lift_result$Ada<-adapred$prob[,1]
head(lift_result)
trellis.par.set(caretTheme())
lift_obj<-lift(Class~DT+RF+Ada, data=lift_result)
ggplot(lift_obj, value=90)+scale_x_continuous(breaks = seq(0,100,10))
result<-resamples(CM1,CM2,CM3)
result<-resamples(list(CM1,CM2,CM3))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/3.PA/CA/data")
pacman::p_load(tidyverse, readxl, lubridate, mice, caret, rpart, randomForest, fastAdaboost, ROCR, mlbench)
result<-resamples(list(CM1,CM2,CM3))
result<-resamples(list(DTmodel,RFmodel,Adamodel))
resamples(list(DTmodel,RFmodel,Adamodel))
DTmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training,method="rpart")
DTmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training,method="rpart")
DTpred<-predict(DTmodel, validation, type="class")
RFmodel<-train(Insp~Val+Quant+Missing+unit_price+med_price+iqr+relative_price, data=training, method="rf")
X<-as.matrix(iris[1:150,1:4])
pcaX<-pca(X)
pcaX<-princomp(X)
svdX<-svd(X)
summary(pcaX)
str(pcaX)
pcaX$scale
pcaX$loadings
pcaX$scores
summary(svdX)
str(svdX)
irisPCA<-data.frame(pcaX$scores, iris$Species)
head(irisPCA)
library(ggplot2)
ggplot(irisPCA, aes(x=Comp.1, y=Comp.2, color=iris.Species))+geom_point()
pcaX$scale
svdX$v
pcaX$loadings
diag(d)
diag(svdX$d)
svdX$u*diag(svdX$d)
svdX$u %*% diag(svdX$d)
pcaX$scale
pcaX$loadings
diag(svdX$d) %*% t(diag(svd$d))
diag(svdX$d) %*% t(diag(svdX$d))
diag(svdX$d) %*% t(diag(svdX$v))
diag(svdX$d) %*% t(svdX$v)
pcaX$scores
svdX$v %*% t(svdX$v)
pcaX$scale
pcaX$loadings
c<-t(X) %*% X/149
svdc<-svd(c)
summary(svdc)
str(svdc)
svdc$u
svdc$v
head(pcaX$scores)
head(X %*% t(svdc$u))
head(X)
head(X %*% svdc$u)
head(pcaX$scores)
svdc$d
svdX$d
svdX$d^2/149
test<-data.matrix(seq(3),seq(3))
test
test<-data.matrix(seq(3),seq(3))
test
?data.matrix
seq(3)
test<-data.matrix(seq(3),seq(3)*2)
test
test<-data.matrix(x=seq(3),y=seq(3))
test<-data.frame(x=seq(3),y=seq(3))
test
pca(test)
prcomp(test)
pcatest<-prcomp(test)
pcatest$scale
pcatest$x
getwd()
install.packages("tidytext")
install.packages("shinyjs")
shiny::runApp('Desktop/Shopify/Recommendation')
shiny::runApp('Desktop/Shopify/Recommendation')
runApp('Desktop/Shopify/Recommendation')
setwd("~/Desktop/Shopify")
dir()
CBF_recommendations_top100<-read.csv("CBF_recommendations_top100.csv", stringsAsFactors = FALSE)
save(CBF_recommendations_top100, file="CBF_recommendations_top100.Rdata")
load("CBF_recommendations_top100.Rdata")
head(CBF_recommendations_top100)
CBF_recommendations_top100<-CBF_recommendations_top100[,c(2:4)]
save(CBF_recommendations_top100, file="CBF_recommendations_top100.Rdata")
